# Modelo de Regresi贸n Lineal Segmentada (MRLS)

Este proyecto implementa el Modelo de Regresi贸n Lineal Segmentada (MRLS), una alternativa a las redes neuronales artificiales (RNA) tradicionales. El MRLS modela conjuntos de datos con funciones lineales a trozos, utilizando un proceso de **compresi贸n neuronal** para reducir la complejidad sin comprometer la precisi贸n m谩s all谩 de una tolerancia definida por el usuario.

El n煤cleo de la soluci贸n es el algoritmo de compresi贸n, que transforma un conjunto de datos desordenado (`DataFrame` / `X, Y`) en un diccionario final, altamente optimizado, listo para realizar predicciones.

## Estructura del Proyecto

* **`model.py`**: Contiene la implementaci贸n completa del proceso de entrenamiento (Creaci贸n, Optimizaci贸n, Compresi贸n) y la funci贸n de predicci贸n (`predict`). Este c贸digo genera el diccionario MRLS final que se consume en la web.
* **`index.html`**: Implementaci贸n de la visualizaci贸n en D3.js y JavaScript Vanilla, que muestra el conjunto de datos, la curva de predicci贸n del MRLS (la funci贸n lineal a trozos) y permite interactuar con la funci贸n de predicci贸n en tiempo real.

---

##  Arquitectura del MRLS: El Proceso de Entrenamiento (Compresi贸n)

El entrenamiento del MRLS se logra a trav茅s de cuatro secciones principales, implementadas secuencialmente en `model.py`:

### 1. Creaci贸n del Diccionario Base (Secci贸n I y II)

El MRLS es un modelo no iterativo. El "entrenamiento" comienza ordenando el conjunto de datos de entrada (`X, Y`) de menor a mayor valor de `X`. Esta ordenaci贸n transforma el `DataFrame` inicial en la estructura fundamental del MRLS: un diccionario donde cada punto `(X, Y)` est谩 indexado por su valor `X`.

### 2. Optimizaci贸n (Secci贸n III)

A partir del diccionario base ordenado, se calcula la funci贸n lineal que conecta cada par de puntos adyacentes `(x1, y1)` y `(x2, y2)`.

* **Pendiente (P)**: Representa el **Peso** (`W`) del segmento.
    $$P = \frac{y_2 - y_1}{x_2 - x_1}$$
* **Ordenada al Origen (O)**: Representa el **Sesgo** (`B`) del segmento.
    $$O = y_1 - P \cdot x_1$$

El resultado es un diccionario optimizado donde cada clave `Xn` (excepto la 煤ltima) almacena la tupla `(P, O)` que define el segmento que comienza en `Xn`.

### 3. Compresi贸n sin P茅rdida (Invarianza Geom茅trica - Secci贸n IV)

Este paso elimina la redundancia geom茅trica del modelo. Si tres puntos consecutivos `(X_{n-1}, X_n, X_{n+1})` se encuentran sobre la misma l铆nea recta (es decir, el segmento de $X_{n-1}$ tiene la misma Pendiente que el segmento de $X_n$), el punto intermedio $X_n$ es redundante.

* **Criterio:** Si $\text{Pendiente}(X_{n-1}) \approx \text{Pendiente}(X_n)$, se elimina el punto $X_n$.
* **Resultado:** Se eliminan "neuronas" intermedias que no contribuyen a un cambio en la direcci贸n de la curva, logrando una compresi贸n del diccionario **sin p茅rdida** de informaci贸n geom茅trica.

### 4. Compresi贸n con P茅rdida (Criterio Humano - Secci贸n V)

Este es el paso de mayor compresi贸n, donde se aplica un **criterio humano** (la tolerancia $\epsilon$) para eliminar puntos cuya contribuci贸n al modelo es m铆nima.

* **Tolerancia ($\epsilon$):** Un valor de error m谩ximo aceptable (por ejemplo, $0.03$).
* **Proceso:** El algoritmo intenta eliminar un punto $X_{\text{actual}}$ y "estirar" el segmento lineal anterior (`P_{prev}, O_{prev}`) hasta $X_{\text{actual}}$.
* **Criterio de Permanencia:** El punto $X_{\text{actual}}$ se considera **Relevante** y se mantiene si la predicci贸n del segmento anterior extendido (`Y_{\text{hat}}`) genera un error absoluto superior a la tolerancia $\epsilon$ respecto al valor original (`Y_{\text{true}}`) en ese punto.

$$\text{Error} = | Y_{\text{true}} - Y_{\text{hat}} |$$

Si $\text{Error} > \epsilon$, el punto se mantiene. Si $\text{Error} \le \epsilon$, se elimina (compresi贸n con p茅rdida).

##  Predicci贸n y Generalizaci贸n (Secci贸n VII)

La funci贸n `predict(X)` utiliza el diccionario MRLS final y comprimido.

1.  **B煤squeda del Segmento Activo:** Para una nueva entrada $X$, el modelo encuentra la clave $X_n$ m谩s pr贸xima y menor o igual a $X$ ($X_n \le X$). Esta $X_n$ define el segmento lineal activo `(P, O)`.
2.  **Ecuaci贸n Maestra:** Se aplica la f贸rmula lineal para obtener la predicci贸n $Y_{\text{predicha}}$.

$$Y_{\text{predicha}} = X \cdot P + O$$

### Generalizaci贸n (Extrapolaci贸n)

El MRLS maneja la extrapolaci贸n fuera de los l铆mites de entrenamiento (Secci贸n VII) de la siguiente manera:

* **Extremo Menor:** Si $X$ es menor que el valor m铆nimo de entrenamiento ($X < X_{\text{min}}$), se extiende el primer segmento lineal (definido por $X_{\text{min}}$) al infinito negativo.
* **Extremo Mayor:** Si $X$ es mayor que el valor m谩ximo de entrenamiento ($X > X_{\text{max}}$), se extiende el 煤ltimo segmento lineal v谩lido (definido por $X_{\text{max-1}}$) al infinito positivo.
