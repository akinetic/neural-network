<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLRM Technical Manual (V5.10b)</title>
    <style>
        /* Usando la fuente y estilos originales */
        body { font-family: 'Inter', sans-serif; background-color: #f7f9fc; color: #1e293b; padding: 20px; }
        .manual-container { max-width: 900px; margin: 0 auto; background: #ffffff; padding: 30px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); }
        h1 { font-size: 2.2em; border-bottom: 3px solid #3b82f6; padding-bottom: 10px; margin-bottom: 20px; color: #1e3a8a; }
        h2 { font-size: 1.8em; color: #1f2937; margin-top: 30px; }
        h3 { font-size: 1.4em; color: #374151; margin-top: 20px; }
        pre { background: #eef2ff; border-left: 4px solid #3b82f6; padding: 15px; overflow-x: auto; border-radius: 6px; font-size: 0.9em; }
        code { background: #eef2ff; padding: 2px 4px; border-radius: 3px; }
        ul { list-style-type: disc; margin-left: 20px; }
        /* Estilo para las variables matemáticas (como P y O) */
        .math-var { font-style: italic; font-weight: bold; }
    </style>
</head>
<body>
    <div class="manual-container">
        <h1>SLRM-LOGOS Technical Manual (V5.10b)</h1>
        <h2>Segmented Linear Regression Model (SLRM) Core Architecture</h2>

        <p>The Segmented Linear Regression Model (SLRM), driven by the deterministic Logos Core algorithm, is a fast and efficient solution for the compression and modeling of one-dimensional data (Time Series, calibration curves, etc.).</p>

        <p>It utilizes the <strong>Minimum Required Line Segments (MRLS)</strong> technique to represent datasets with the smallest possible number of linear segments, meeting a user-defined error tolerance (<span class="math-var">&epsilon;</span>).</p>

        <hr style="border: 0; border-top: 1px dashed #e5e7eb; margin: 30px 0;">

        <h3>Key Features (SLRM V5.10b)</h3>
        <ul>
            <li><strong>Verification and Robustness:</strong> Versión V5.10b verificada y probada con correcciones críticas en el manejo del error máximo en compresión Lossy.</li>
            <li><strong>Speed:</strong> The core compression process is non-iterative and deterministic, relying on NumPy for optimal training speed, making it an <strong>Instant Training</strong> model.</li>
            <li><strong>Compression (Lossless/Lossy):</strong> Implements both exact geometric compression (<code>_lossless_compression</code>) and tolerance-based compression (<code>_lossy_compression</code>).</li>
            <li><strong>Prediction Optimized:</strong> Uses an <strong>LRU (Least Recently Used)</strong> prediction cache for dramatically accelerating real-time inference of repeated or nearby points.</li>
            <li><strong>Data Integrity:</strong> Includes an initial data purification stage (<code>_clean_and_sort_data</code>) to handle duplicates (averaging Y values for the same X) and sort the data by X.</li>
            <li><strong>Full Interpretability:</strong> The model is a "transparent box," storing explicit knowledge (Slope <span class="math-var">P</span> and Intercept <span class="math-var">O</span>) for every segment.</li>
        </ul>

        <h3>Training Process Stages (V5.10b)</h3>
        <p>The <code>train_slrm</code> function executes a three-stage compression pipeline:</p>

        <ol>
            <li><strong>Purification & Sorting (<code>_clean_and_sort_data</code>):</strong>
                <ul>
                    <li>Converts input data into a clean, sorted sequence of points.</li>
                    <li>Handles X duplicates by averaging their corresponding Y values.</li>
                </ul>
            </li>
            <li><strong>Lossless Compression (<code>_lossless_compression</code>):</strong>
                <ul>
                    <li><strong>Geometric Invariance:</strong> Identifica y elimina todos los puntos intermedios que son geométricamente colineales (puntos críticos de quiebre).</li>
                    <li>El resultado es la <strong>Base de Breakpoints</strong> que preserva la precisión original.</li>
                </ul>
            </li>
            <li><strong>Lossy Compression (MRLS, <code>_lossy_compression</code>):</strong>
                <ul>
                    <li>Aplica el criterio de error humano <span class="math-var">&epsilon;</span> sobre la Base de Breakpoints.</li>
                    <li>Utiliza la técnica de <strong>Segmentos de Línea Mínimos Requeridos (MRLS)</strong> para extender segmentos hasta que el error de interpolación exceda <span class="math-var">&epsilon;</span>.</li>
                    <li><strong>El modelo final</strong> (<span class="math-var">P</span>, <span class="math-var">O</span>, <span class="math-var">X<sub>end</sub></span>) es generado y el máximo error real (<span class="math-var">Error<sub>max</sub></span>) es retornado.</li>
                </ul>
            </li>
        </ol>

        <h3 style="margin-top: 40px;">Usage Quick Guide</h3>
        <p>The model is trained and used via the <code>train_slrm</code> and <code>predict_slrm</code> functions in the <code>slrm-logos.py</code> file.</p>

        <h4>Requirements:</h4>
        <p>You need to have Python and the NumPy library installed.</p>
        <pre><code>pip install numpy</code></pre>

        <h4>1. Training (V5.10b)</h4>
        <p>Define your input data and the tolerance (<span class="math-var">&epsilon;</span>).</p>
        <pre><code>from slrm_logos import train_slrm

INPUT_DATA = [
    [-8.00, -4.00], [4.00, 5.0], [6.00, 18.0], [10.00, 27.00]
    # ... more points
]

# Train the model. It returns the final model dictionary, the original points, and the max error achieved.
final_model, original_points, max_error_achieved = train_slrm(INPUT_DATA, epsilon=0.03) 

# El resultado 'final_model' es un diccionario {X_start: [P, O, X_end]} 
# que define explícitamente cada segmento.</code></pre>

        <h4>2. Prediction (V5.10b)</h4>
        <p>Use el diccionario del modelo (<code>final_model</code>) para obtener predicciones para cualquier punto X. El caché LRU se gestiona internamente en la función <code>predict_slrm</code>.</p>
        <pre><code>from slrm_logos import predict_slrm

x_test = 4.5
result = predict_slrm(x_test, final_model, original_points)

print(f"Prediction for X={result['x_in']}: Y={result['y_pred']:.4f}")
print(f"Active Segment: P={result['slope_P']:.4f}, O={result['intercept_O']:.4f}")
print(f"Cache Hit: {result['cache_hit']}") # Muestra si la predicción vino del caché</code></pre>
        <!-- GitHub Links -->
        <footer class="mt-12 pt-6 border-t border-gray-300">
            <h3 class="text-xl font-semibold mb-3 text-blue-700">Resources and Reference Scripts:</h3>
            <ul class="space-y-2 text-gray-500">
                <li>
                    <a href="https://github.com/akinetic/neural-network/" target="_blank" class="text-blue-600 hover:text-blue-800 transition duration-150 ease-in-out font-medium">
                        &#9993; Main Project Repository
                    </a>
                </li>
                <li>
                    <a href="https://github.com/akinetic/neural-network/blob/main/slrm-logos.py" target="_blank" class="text-blue-600 hover:text-blue-800 transition duration-150 ease-in-out font-medium">
                        &#x1F4BB; Production SLRM Script (slrm-logos.py)
                    </a>
                </li>
                <li>
                    <a href="https://github.com/akinetic/neural-network/blob/main/slrm_performance_report.html" target="_blank" class="text-blue-600 hover:text-blue-800 transition duration-150 ease-in-out font-medium">
                        &#x1F4C4; Performance and Efficiency Report (slrm_performance_report.html)
                    </a>
                </li>
            </ul>
        </footer>
    </div>
</body>
</html>
